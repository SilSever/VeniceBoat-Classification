{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "family_classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_CCv0ONrdO2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://SilSever:Milano15!@github.com/SilSever/VeniceBoatDataset.git\n",
        "\n",
        "from VeniceBoatDataset.dataset_manipulation import read_images\n",
        "from VeniceBoatDataset.models import SmallerVGGNet\n",
        "from VeniceBoatDataset.metrics import f1, confusion_matrices\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib\n",
        " \n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.models import load_model\n",
        "import imutils\n",
        "\n",
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "EPOCHS = 50\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "IMAGE_DIMS = (180, 180, 3) #Height x Width x RGB\n",
        "\n",
        "\n",
        "\n",
        "#PREPROCESING CNN\n",
        "data, labels = read_images('VeniceBoatDataset/sc5-tensorflow', 3, IMAGE_DIMS[0], IMAGE_DIMS[1])\n",
        "\n",
        "class_name = list(set(labels))\n",
        "\n",
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels = np.array(labels)\n",
        "print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
        "    data.nbytes / (1024 * 1000.0)))\n",
        " \n",
        "# binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        " \n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,\n",
        "    labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
        "    horizontal_flip=True, fill_mode=\"nearest\")\n",
        "\n",
        "\n",
        "\n",
        "#TRAINING MODEL\n",
        "\n",
        "# initialize the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2], classes=labels.shape[1])\n",
        "opt = tf.train.AdamOptimizer(learning_rate=INIT_LR)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\", f1])\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator( aug.flow(trainX, trainY, batch_size=BS),\n",
        "                          validation_data=(testX, testY),\n",
        "                          steps_per_epoch=len(trainX) // BS,\n",
        "                          epochs=EPOCHS, \n",
        "                          verbose=1)\n",
        "\n",
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save('VeniceBoatDataset/model')\n",
        " \n",
        "# save the label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "f = open('VeniceBoatDataset/label', \"wb\")\n",
        "f.write(pickle.dumps(lb))\n",
        "f.close()\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"f1\"], label=\"f1_score\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_f1\"], label=\"val_f1_score\")\n",
        "plt.title(\"Training Accuracy and F1 score\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy/f1\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig('VeniceBoatDataset/plot')\n",
        "\n",
        "#plot confusion matrix\n",
        "cm = confusion_matrices(model, testY, testX)\n",
        "metrics.plot_confusion_matrix(cm, class_name)\n",
        "\n",
        "\n",
        "#TESTING MODEL\n",
        "# load the image\n",
        "path = 'VeniceBoat-Dataset/sc5-test-tensorflow/Pleasurecraft/Topa/'\n",
        "images = os.listdir(path)\n",
        "im_path = path + images[0]\n",
        "\n",
        "image = cv2.imread(im_path)\n",
        "output = image.copy()\n",
        "\n",
        "# pre-process the image for classification\n",
        "image = cv2.resize(image, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)\n",
        "\n",
        "# load the trained convolutional neural network and the label\n",
        "# binarizer\n",
        "print(\"[INFO] loading network...\")\n",
        "model = load_model('VeniceBoat-Dataset/model-family')\n",
        "lb = pickle.loads(open('VeniceBoat-Dataset/label-family', \"rb\").read())\n",
        " \n",
        "# classify the input image\n",
        "print(\"[INFO] classifying image...\")\n",
        "\n",
        "proba = model.predict(image)[0]\n",
        "idx = np.argmax(proba)\n",
        "label = lb.classes_[idx]\n",
        "\n",
        "label = \"{}: {:.2f}% ({})\".format(label, proba[idx] * 100, 'correct')\n",
        "print(\"[INFO] {}\".format(label))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}